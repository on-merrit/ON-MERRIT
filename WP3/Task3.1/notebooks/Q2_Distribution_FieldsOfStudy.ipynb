{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This will create plots for institutions of universities in THE WUR univs only and for the period of 2007-2017. The input dataset contains info of THE WUR univs only but for any period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is to be compatible with other analysis questions which used dataset from the period of 2007 to 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: On-MERRIT DoW mentions Agriculture, Climate and Health but MAG has Agriculture, Climatology and Medicine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question : How are papers published by the universities distributed across the three scientific disciplines of our choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard path wrangling to be able to import project config and sources\n",
    "import os\n",
    "import sys\n",
    "from os.path import join\n",
    "root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(root)\n",
    "print('Project root: {}'.format(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(join(root,\"spark/shared/\"))\n",
    "from MAG_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import json\n",
    "\n",
    "# Installed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import rc,rcParams\n",
    "from matplotlib.patches import Rectangle\n",
    "import swifter\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "from statistics import mean\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = None\n",
    "with open(join(root,\"spark/config.json\")) as fp:\n",
    "    cfg = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames_for_plot = {\n",
    "    \"austria\" : \"Austria\",\n",
    "    \"brazil\" : \"Brazil\",\n",
    "    \"germany\" : \"Germany\",\n",
    "    \"india\" : \"India\",\n",
    "    \"portugal\" : \"Portugal\",\n",
    "    \"russia\" : \"Russia\",\n",
    "    \"uk\" : \"UK\",\n",
    "    \"usa\" : \"USA\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = join(root,\"documents/analysis/dataset_selection_question2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory to save results\n",
    "os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_years = [2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the external file -- fos_hierarchy to use for selecting papers that belong to our field of study choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic = lambda x: ast.literal_eval(x)\n",
    "conv = {\"fieldofstudyid\": int, \"normalizedname\": str, \"level\": int, \"child_ids\": str}  \n",
    "\n",
    "\n",
    "fos_hierarchy = pd.read_csv(join(root,\"data/external/fos_hierarchy.csv\"), header=0, converters=conv, sep=\",\")  # object means string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fos_hierarchy.head(17).tail(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fos_hierarchy['child_ids_list'] = [[int(idx) for idx in x.split(\",\") if x!=''] for x in fos_hierarchy['child_ids']]\n",
    "\n",
    "fos_hierarchy = fos_hierarchy.drop('child_ids', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fos_hierarchy.head(17).tail(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the path to all the topmost parent (i.e. whose fos_name is eithere agriculture or climatology or medicine) for any the fos id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_fos_names = [\"medicine\",\"climatology\", \"agriculture\"]\n",
    "\n",
    "relevant_fos_ids = fos_hierarchy[fos_hierarchy['normalizedname'].isin(relevant_fos_names)]['fieldofstudyid'].values.tolist()\n",
    "# print(relevant_fos_ids)\n",
    "\n",
    "relevant_fos_dict = {}\n",
    "for i in relevant_fos_ids:\n",
    "    relevant_fos_dict[i] = fos_hierarchy[fos_hierarchy['fieldofstudyid']==i]['normalizedname'].values.tolist()[0]\n",
    "print(relevant_fos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_immediate_parent_ids(fos_id):\n",
    "    '''\n",
    "    Returns a list of immediate parents (fieldofstudyid) for a given fos_id.\n",
    "    '''\n",
    "    # https://stackoverflow.com/a/41518959/530399\n",
    "    mask = fos_hierarchy.child_ids_list.apply(lambda x: fos_id in x)\n",
    "    all_parent_fos_df = fos_hierarchy[mask]\n",
    "    all_parent_ids = all_parent_fos_df.fieldofstudyid.values.tolist()\n",
    "    return all_parent_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fos_parents(fos_id):\n",
    "    '''\n",
    "    For a given fos_id, explores the hierarchy all the way to the top to find parents that belong to either agriculture, climatology or medicine. \n",
    "    '''\n",
    "    ids_up_hierarchy = []\n",
    "    found_names = set()\n",
    "    \n",
    "    if fos_id in relevant_fos_ids:\n",
    "        found_names.add(relevant_fos_dict[fos_id])\n",
    "        return ids_up_hierarchy, found_names\n",
    "    else:\n",
    "        immediate_parents = get_immediate_parent_ids(fos_id)\n",
    "        \n",
    "        if not immediate_parents: # if we have reached to the top parent but it is still not the fos of our choice\n",
    "            return [], set()\n",
    "        else:\n",
    "            to_explore_ids = []\n",
    "            for i in immediate_parents:\n",
    "                if i in relevant_fos_ids:\n",
    "                    found_names.add(relevant_fos_dict[i])\n",
    "                else:\n",
    "                    ids_up_hierarchy.append(i)\n",
    "                    to_explore_ids.append(i)\n",
    "            \n",
    "#             print(\"immediate parent ids = \"+str(immediate_parents) + \" and to explore ids = \"+str(to_explore_ids))\n",
    "            \n",
    "            for j in to_explore_ids:\n",
    "                x, y = get_fos_parents(j)\n",
    "                ids_up_hierarchy.extend(x)\n",
    "                found_names = (found_names | y)  # | means union\n",
    "            \n",
    "        return ids_up_hierarchy, found_names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# eg_fosid = 49204034\n",
    "# eg_fosid = 2909824727\n",
    "eg_fosid = 2781369281\n",
    "# eg_fosid = 2778072252\n",
    "# eg_fosid = 40520153\n",
    "# eg_fosid = 2\n",
    "\n",
    "parent_ids, parent_names = get_fos_parents(eg_fosid)\n",
    "print(parent_ids, parent_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fosids = []\n",
    "all_fosids.extend(y for x in fos_hierarchy['child_ids_list'].tolist() for y in x)\n",
    "all_fosids.extend(x for x in fos_hierarchy['fieldofstudyid'].tolist())\n",
    "all_fosids = list(set(all_fosids))\n",
    "# len(all_fosids)\n",
    "\n",
    "all_fosids_parentnames= {}\n",
    "for x in all_fosids:\n",
    "    _, parent_names = get_fos_parents(x)\n",
    "    all_fosids_parentnames[x] = parent_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_disciplines(input_fos_id):\n",
    "    is_medicine = 0\n",
    "    is_climatology = 0\n",
    "    is_agriculture = 0\n",
    "    if input_fos_id in all_fosids_parentnames:\n",
    "        parent_names = all_fosids_parentnames[input_fos_id]\n",
    "        if \"medicine\" in parent_names:\n",
    "            is_medicine = 1\n",
    "        if \"climatology\" in parent_names:\n",
    "            is_climatology = 1\n",
    "        if \"agriculture\" in parent_names:\n",
    "            is_agriculture = 1\n",
    "    return str(is_medicine)+\",\"+str(is_climatology)+\",\"+str(is_agriculture)\n",
    "\n",
    "\n",
    "print(map_disciplines(eg_fosid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of count of papers in each of the three disciplines for  publications coming from each university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_univ_papers_disciplines_counts(country_papers_fos_df, univs_name):    \n",
    "    '''\n",
    "    Get the plot of count of papers in each discipline from each university in the input country.\n",
    "    '''\n",
    "    univs_info = {}\n",
    "    \n",
    "    univs_not_found = []\n",
    "    univs_found = []\n",
    "    \n",
    "    for org_univ_name in set(univs_name):  # remove duplicate univ names in the THE list, if any\n",
    "#         print(org_univ_name)\n",
    "\n",
    "        THE_univ_name_normalised = mag_normalisation_institution_names(org_univ_name)\n",
    "    \n",
    "        '''\n",
    "        The dataframe that will be selected for the current univ is either :\n",
    "        1. When the MAG normalizedname column matches to THE_univ_name_normalised\n",
    "        or\n",
    "        2. When the MAG normalised(wikiname) matches to THE_univ_name_normalised -- this matches English names (in MAG wiki links as well as THE) of non English name (in MAG normalisedname or displayname) universities.\n",
    "        '''\n",
    "        univ_papers_df_set1 = country_papers_fos_df[country_papers_fos_df['normalizedname']==THE_univ_name_normalised]\n",
    "        \n",
    "        univ_papers_df_set2 = country_papers_fos_df[country_papers_fos_df['normalizedwikiname']==THE_univ_name_normalised]\n",
    "        \n",
    "        # The records in two sets can be the exactly the same \n",
    "        # Concat and remove exact duplicates  -- https://stackoverflow.com/a/21317570/530399\n",
    "        univ_papers_df = pd.concat([univ_papers_df_set1, univ_papers_df_set2]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "#         Put additional criteria that these papers are from 2007 till 2017\n",
    "        univ_papers_df = univ_papers_df[univ_papers_df['year'].isin(study_years)]\n",
    "        \n",
    "        \n",
    "        # For those I couldn't match/find their name, it is not fair to say that their count of papers in any discipline was 0. Should be excluded from the graph.\n",
    "        if len(univ_papers_df)==0:\n",
    "            univs_not_found.append(org_univ_name+\"    @    \"+THE_univ_name_normalised)\n",
    "        else:\n",
    "            univs_found.append(org_univ_name)\n",
    "            \n",
    "            # because there can be multiple records with the same paperid for the same university\n",
    "            count_total_univ_papers = len(univ_papers_df.drop_duplicates(subset=['paperid']))\n",
    "            \n",
    "            univs_info[org_univ_name] = {}\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # Experimental\n",
    "#             univ_papers_df = univ_papers_df.head(10)\n",
    "            \n",
    "            # Get the fieldofstudy for each paper in the univ_papers_df dataframe. This dataframe can contain multiple records for the same paperid because a paper could belong to multiple fields of study -- https://stackoverflow.com/a/27385043/530399\n",
    "#         univ_papers_df['is_medicine'], univ_papers_df['is_climatology'], univ_papers_df['is_agriculture'] = zip(*univ_papers_df['fieldofstudyid'].map(map_disciplines))\n",
    "            univ_papers_df['paper_fos_names_flag'] = univ_papers_df['fieldofstudyid'].swifter.apply(map_disciplines)\n",
    "            univ_papers_df['is_medicine'], univ_papers_df['is_climatology'], univ_papers_df['is_agriculture'] = univ_papers_df['paper_fos_names_flag'].str.split(',').str\n",
    "            univ_papers_df = univ_papers_df.astype({'is_medicine':int,'is_climatology':int,'is_agriculture':int})\n",
    "            \n",
    "            \n",
    "#           int casting needed to convert numpy int (json-incompatible) to python int\n",
    "            count_medicine_univ_papers = int(univ_papers_df['is_medicine'].sum())\n",
    "            count_climatology_univ_papers = int(univ_papers_df['is_climatology'].sum())\n",
    "            count_agriculture_univ_papers = int(univ_papers_df['is_agriculture'].sum())\n",
    "            \n",
    "            \n",
    "\n",
    "            univ_medicine_percent = (count_medicine_univ_papers*100.00)/count_total_univ_papers\n",
    "            univ_climatology_percent = (count_climatology_univ_papers*100.00)/count_total_univ_papers\n",
    "            univ_agriculture_percent = (count_agriculture_univ_papers*100.00)/count_total_univ_papers\n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "            univs_info[org_univ_name][\"count_medicine_papers\"] = count_medicine_univ_papers\n",
    "            univs_info[org_univ_name][\"percent_medicine_papers\"] = univ_medicine_percent\n",
    "            \n",
    "            univs_info[org_univ_name][\"count_climatology_papers\"] = count_climatology_univ_papers\n",
    "            univs_info[org_univ_name][\"percent_climatology_papers\"] = univ_climatology_percent\n",
    "            \n",
    "            univs_info[org_univ_name][\"count_agriculture_papers\"] = count_agriculture_univ_papers\n",
    "            univs_info[org_univ_name][\"percent_agriculture_papers\"] = univ_agriculture_percent\n",
    "            \n",
    "            univs_info[org_univ_name][\"count_total_papers\"] = count_total_univ_papers\n",
    "        \n",
    "    return univs_info, univs_not_found, univs_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries_all_univs_fos_info = {}\n",
    "all_countries_univs_found_not_found = {}\n",
    "\n",
    "for country_name,univs_name in cfg['data']['all_THE_WUR_institutions_by_country'].items():\n",
    "    print(\"\\nProcesing for dataset of univs in \"+country_name+\"\\n\")\n",
    "    all_countries_univs_found_not_found[country_name] =  {}\n",
    "    \n",
    "    # CSV has repeated header from multiple partitions of the merge on pyspark csv output. Hence need to treat as string.\n",
    "    country_papers_fos_df = pd.read_csv(join(root,\"data/processed/fsid_\"+country_name+\"_papers.csv\"), header=0, sep=\",\", dtype={\"year\": object, \"wikipage\": object, \"normalizedwikiname\": object, 'fieldofstudyid': object,  \"score\": object})  # object means string\n",
    "    \n",
    "        \n",
    "    # Then eliminate problematic lines\n",
    "    #  temp fix until spark csv merge header issue is resolved -- the header line is present in each re-partition's output csv\n",
    "    country_papers_fos_df.drop(country_papers_fos_df[country_papers_fos_df.paperid == \"paperid\"].index, inplace=True)\n",
    "    # Then reset dtypes as needed.\n",
    "    country_papers_fos_df = country_papers_fos_df.astype({'year':int})\n",
    "    country_papers_fos_df = country_papers_fos_df.astype({'fieldofstudyid':int})\n",
    "    country_papers_fos_df = country_papers_fos_df.astype({'score':float})\n",
    "    \n",
    "    \n",
    "    univs_info, univs_not_found, univs_found = get_univ_papers_disciplines_counts(country_papers_fos_df, univs_name)\n",
    "    \n",
    "    all_countries_all_univs_fos_info[country_name] =  univs_info\n",
    "    \n",
    "    count_total_univs = len(univs_not_found) + len(univs_found)\n",
    "    \n",
    "    not_found_details = {}\n",
    "    not_found_details['univ_names'] = univs_not_found\n",
    "    not_found_details['count_univs'] = len(univs_not_found)\n",
    "    not_found_details['percent_univs'] = (len(univs_not_found)*100.00)/count_total_univs\n",
    "    \n",
    "    found_details = {}\n",
    "    found_details['univ_names'] = univs_found\n",
    "    found_details['count_univs'] = len(univs_found)\n",
    "    found_details['percent_univs'] = (len(univs_found)*100.00)/count_total_univs\n",
    "    \n",
    "    \n",
    "    all_details = {}\n",
    "    all_details['count_univs'] = count_total_univs\n",
    "    \n",
    "    all_countries_univs_found_not_found[country_name]['not_found'] = not_found_details\n",
    "    all_countries_univs_found_not_found[country_name]['found'] = found_details\n",
    "    all_countries_univs_found_not_found[country_name]['all'] = all_details\n",
    "    \n",
    "    \n",
    "        \n",
    "    print(\"Computed counts of papers in each disciplines for all univs in \"+country_name+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write text files with the infos\n",
    "\n",
    "with open(join(output_dir,'all_countries_univs_found_not_found.txt'), 'w') as file:\n",
    "     file.write(json.dumps(all_countries_univs_found_not_found, sort_keys=True, indent=4, ensure_ascii=False))\n",
    "        \n",
    "with open(join(output_dir,'all_countries_all_univs_fos_info.txt'), 'w') as file:\n",
    "     file.write(json.dumps(all_countries_all_univs_fos_info, sort_keys=True, indent=4, ensure_ascii=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from previously saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(output_dir,'all_countries_all_univs_fos_info.txt')) as file:\n",
    "     all_countries_all_univs_fos_info = json.load(file)\n",
    "        \n",
    "print(all_countries_all_univs_fos_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create bar plot for each of the countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_bar_with_value(ax, rects, value_labels):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for i in range(len(rects)):\n",
    "        rect = rects[i]\n",
    "        label_value = value_labels[i]\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*rect.get_height(),\n",
    "                '%s' % label_value,\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "\n",
    "def create_fos_count_distribution_bar_chart(univs_details, save_fname, x_label, save_file=True):\n",
    "    # https://chrisalbon.com/python/data_visualization/matplotlib_grouped_bar_plot/\n",
    "    # https://stackoverflow.com/a/42498711/530399\n",
    "    \n",
    "    univs_name = [x for x in univs_details.keys()]\n",
    "    univs_data = univs_details.values()\n",
    "    univs_agriculture_counts = [x['count_agriculture_papers'] for x in univs_data]\n",
    "    univs_climatology_counts = [x['count_climatology_papers'] for x in univs_data]\n",
    "    univs_medicine_counts = [x['count_medicine_papers'] for x in univs_data]\n",
    "    \n",
    "    \n",
    "    raw_data = {'univs_name': univs_name,\n",
    "        'univs_agriculture_counts': univs_agriculture_counts,\n",
    "        'univs_climatology_counts' : univs_climatology_counts,\n",
    "        'univs_medicine_counts': univs_medicine_counts,\n",
    "        'percent_agriculture_papers': percent_agriculture_papers,\n",
    "        'percent_climatology_papers': percent_climatology_papers,\n",
    "        'percent_medicine_papers': percent_medicine_papers\n",
    "               }\n",
    "    df = pd.DataFrame(raw_data, columns = ['univs_name', 'univs_agriculture_counts', 'univs_climatology_counts', 'univs_medicine_counts', 'percent_agriculture_papers', 'percent_climatology_papers', 'percent_medicine_papers'])\n",
    "    \n",
    "    # Compute proportion of each the fos counts for the university\n",
    "    df['percent_agriculture_papers'] = df['percent_agriculture_papers'] *100\n",
    "#     df['proportion_univs_climatology'] = df['percent_climatology_papers'] *100\n",
    "#     df['proportion_univs_medicine'] = df['percent_medicine_papers'] *100\n",
    "    \n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    # sort the df based on proportion of agriculture fos\n",
    "    df = df.sort_values('proportion_univs_agriculture', ascending=False)[['univs_name', 'univs_agriculture_counts','univs_climatology_counts', 'univs_medicine_counts', 'proportion_univs_agriculture']]\n",
    "#     df_sorted_climatology = df.sort_values('proportion_univs_climatology', ascending=False)[['univs_name', 'univs_agriculture_counts','univs_climatology_counts', 'univs_medicine_counts', 'proportion_univs_climatology']]\n",
    "#     df_sorted_medicine = df.sort_values('proportion_univs_medicine', ascending=False)[['univs_name', 'univs_agriculture_counts','univs_climatology_counts', 'univs_medicine_counts', 'proportion_univs_medicine']]\n",
    "    \n",
    "    # Setting the positions and width for the bars\n",
    "    pos = list(range(len(df['univs_name']))) \n",
    "    width = 0.25 \n",
    "\n",
    "    # Plotting the bars\n",
    "    fig, ax = plt.subplots(figsize=(25,10))\n",
    "\n",
    "    # Create a bar with agriculture_count data,\n",
    "    # in position pos,\n",
    "    oa_reference_count_bars = ax.bar(pos, \n",
    "            #using df['proportion_univs_agriculture'] data,\n",
    "            df['univs_agriculture_counts'], \n",
    "            # of width\n",
    "            width, \n",
    "            # with alpha 0.5\n",
    "            alpha=0.5, \n",
    "            # with color\n",
    "            color='green', \n",
    "            )\n",
    "    # Set heights based on the percentages\n",
    "    fos_agriculture_proportion_value_labels = [str(int(x))+\"%\" for x in df['proportion_univs_agriculture'].values.tolist()]\n",
    "#     fos_agriculture_proportion_value_labels = [str(int(x))+\"%\" for x in df['proportion_univs_climatology'].values.tolist()]\n",
    "#     fos_agriculture_proportion_value_labels = [str(int(x))+\"%\" for x in df['proportion_univs_medicine'].values.tolist()]\n",
    "\n",
    "    # Create a bar with climatology_count data,\n",
    "    # in position pos + some width buffer,\n",
    "    plt.bar([p + width for p in pos], \n",
    "            #using df['univs_climatology_counts'] data,\n",
    "            df['univs_climatology_counts'],\n",
    "            # of width\n",
    "            width, \n",
    "            # with alpha 0.5\n",
    "            alpha=0.5, \n",
    "            # with color\n",
    "            color='red', \n",
    "            )\n",
    "    \n",
    "    # Create a bar with medicine_count data,\n",
    "    # in position pos + 2*some width buffer,\n",
    "    plt.bar([p + 2*width for p in pos], \n",
    "            #using df['univs_medicine_counts'] data,\n",
    "            df['univs_medicine_counts'],\n",
    "            # of width\n",
    "            width, \n",
    "            # with alpha 0.5\n",
    "            alpha=0.5, \n",
    "            # with color\n",
    "            color='blue', \n",
    "            )\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Set the y axis label\n",
    "    ax.set_ylabel('Paper Counts')\n",
    "\n",
    "    # Set the x axis label\n",
    "    ax.set_xlabel(x_label)\n",
    "\n",
    "    # Set the position of the x ticks\n",
    "    ax.set_xticks([p + 0.5 * width for p in pos])\n",
    "\n",
    "    # Set the labels for the x ticks\n",
    "    ax.set_xticklabels(df['univs_name'], rotation='vertical')\n",
    "\n",
    "    # Setting the x-axis and y-axis limits\n",
    "    plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "    plt.ylim([0, max(df['univs_agriculture_counts'] + df['univs_climatology_counts'] + df['univs_medicine_counts'])] )\n",
    "\n",
    "    # Adding the legend and showing the plot\n",
    "    plt.legend(['Agriculture paper Counts', 'Climatology Paper Counts', 'Medicine Paper Counts'], loc='upper left')\n",
    "    plt.grid()\n",
    "    \n",
    "    label_bar_with_value(ax, oa_reference_count_bars, oa_reference_counts_proportion_value_labels)\n",
    "    \n",
    "    if save_file:\n",
    "        plt.savefig(save_fname+\".png\", bbox_inches='tight', dpi=300)\n",
    "        plt.savefig(save_fname+\".pdf\", bbox_inches='tight', dpi=900)\n",
    "    \n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name = 'austria'\n",
    "univs_details = all_countries_all_univs_fos_info[country_name]\n",
    "\n",
    "\n",
    "create_fos_count_distribution_bar_chart(univs_details, save_fname = join(output_dir,country_name+\"_\"+'foscount_distribution'), x_label = (\"Universities in \"+cnames_for_plot[country_name]+\" -- Ranked by papers in the \"+\"agriculture\"+\" discipline\"), save_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for country_name, univs_details in all_countries_all_univs_fos_info.items():\n",
    "    create_fos_count_distribution_bar_chart(univs_details, save_fname = join(output_dir,country_name+\"_\"+'foscount_distribution'), x_label = (\"Universities in \"+cnames_for_plot[country_name]), save_file=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\\nCompleted!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
