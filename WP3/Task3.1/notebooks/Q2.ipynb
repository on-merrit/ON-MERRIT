{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 2: How are papers from our selected institutions distributed across the three different scientific disciplines (agriculture, climatology and medicine) we chose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard path wrangling to be able to import project config and sources\n",
    "import os\n",
    "import sys\n",
    "from os.path import join\n",
    "root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(root)\n",
    "print('Project root: {}'.format(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import json\n",
    "\n",
    "# Installed\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_normalisation_institution_names(institution_name):\n",
    "        '''\n",
    "        An approximation function to estimate the way MAG normalises university names\n",
    "        :param institution_name: The input name of the institution to normalise as per MAG\n",
    "        :type str\n",
    "        :return: normalised names as in the field \"normalizedname\" of \"affiliations\" table in MAG.\n",
    "        :type str\n",
    "        '''\n",
    "\n",
    "        # Replace non-ascii by ascii. See https://stackoverflow.com/a/3704793/530399\n",
    "        # norm_uname = unicodedata.normalize('NFKD', university_name).encode('ascii', 'ignore')\n",
    "        # https://stackoverflow.com/a/14785625/530399 Python 3 replaced unicode with str\n",
    "        norm_uname = unicodedata.normalize('NFKD', institution_name).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "        norm_uname = norm_uname.lower()\n",
    "        # Only preserve the a-z characters and replace the rest by space\n",
    "        norm_uname = re.sub(r'[^\\x61-\\x7A]+',' ', norm_uname)\n",
    "        norm_uname = norm_uname.strip()\n",
    "\n",
    "        return norm_uname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = None\n",
    "with open(join(root,\"spark/config.json\")) as fp:\n",
    "    cfg = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory to save results\n",
    "output_dir = join(root,\"documents/analysis/dataset_selection_question2\")\n",
    "os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_institutions_paper_count_plot(selected_institutions_papercount_df, paper_count_df, country_name, discipline, output_dir):\n",
    "    \n",
    "    all_insts = paper_count_df['normalizedname'].values.tolist()\n",
    "    all_inst_paper_counts = paper_count_df['paper_counts'].values.tolist()\n",
    "    \n",
    "    selected_insts = selected_institutions_papercount_df['normalizedname'].values.tolist()\n",
    "    selected_inst_paper_counts = selected_institutions_papercount_df['paper_counts'].values.tolist()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.plot(all_insts, all_inst_paper_counts, color='blue')\n",
    "    plt.scatter(selected_insts, selected_inst_paper_counts, color='red') # overlay of scatter plot for selected institutions\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Annotate the name of the selected universities to the plot\n",
    "    for i, txt in enumerate(selected_insts):\n",
    "        ax.annotate(txt, (selected_insts[i], selected_inst_paper_counts[i]))\n",
    "    \n",
    "    \n",
    "    ax.set_xlabel(\"Institutions in \"+country_name)\n",
    "    ax.set_ylabel(\"Publication count in \"+discipline+ \" domain\")\n",
    "    \n",
    "\n",
    "    # https://stackoverflow.com/a/12998531/530399\n",
    "    plt.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=False)\n",
    "    \n",
    "    plt.savefig(join(output_dir,country_name+\"_\"+discipline+'.png'), bbox_inches='tight')\n",
    "    plt.savefig(join(output_dir,country_name+\"_\"+discipline+'.pdf'), bbox_inches='tight')\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries_plot = {}\n",
    "\n",
    "for discipline in cfg['data']['fields_of_study']:\n",
    "\n",
    "    all_countries_plot[discipline] = {}\n",
    "    \n",
    "    for country_name,institutions_name in cfg['data']['institutions_by_country'].items():\n",
    "\n",
    "        country_discipline_df = pd.read_csv(join(root,\"data/processed/\"+country_name+\"_\"+discipline+\"_papers.csv\"), header=0, sep=\",\")\n",
    "        \n",
    "        #  temp fix until spark csv merge header issue is resolved\n",
    "        country_discipline_df.drop(country_discipline_df[country_discipline_df.paperid == \"paperid\"].index, inplace=True)\n",
    "    \n",
    "        \n",
    "        paper_count_df = country_discipline_df.groupby('normalizedname').count()[['paperid']].rename(columns={'paperid': 'paper_counts'}).reset_index()  # dataframe of count of papers in current discipline for all institutions in current country. The index of this dataframe is institution normalizedname and has a single column named papers_count\n",
    "        \n",
    "        paper_count_df = paper_count_df.sort_values('paper_counts', ascending=True)\n",
    "        \n",
    "        norm_institute_names=[mag_normalisation_institution_names(x) for x in institutions_name]\n",
    "        selected_institutions_papercount_df = paper_count_df[paper_count_df['normalizedname'].isin(norm_institute_names)]\n",
    "        \n",
    "        \n",
    "        plt_country_institutions = get_institutions_paper_count_plot(selected_institutions_papercount_df, paper_count_df, country_name, discipline, output_dir)\n",
    "        \n",
    "        all_countries_plot[discipline][country_name] = plt_country_institutions\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Saved plot for dataset of \"+discipline+\" in \"+country_name+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries_plot[\"climatology\"][\"netherlands\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries_plot[\"agriculture\"][\"germany\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
