{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This will create plots for institutions of type universities only. The universities list comes from Times Higher Education (THE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question : What % of papers published by our selected universities in selected countries are Open Access?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard path wrangling to be able to import project config and sources\n",
    "import os\n",
    "import sys\n",
    "from os.path import join\n",
    "root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(root)\n",
    "print('Project root: {}'.format(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(join(root,\"spark/shared/\"))\n",
    "from MAG_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import json\n",
    "\n",
    "# Installed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = None\n",
    "with open(join(root,\"spark/config.json\")) as fp:\n",
    "    cfg = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = join(root,\"documents/analysis/jcdl_dataset_question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_OA_percent_bar_chart(oa_percent_dict, save_fname, x_label=None, plt_text=None, display_values=False):\n",
    "    #     https://stackoverflow.com/a/37266356/530399\n",
    "    sort_by_vals = sorted(oa_percent_dict.items(), key=lambda kv: kv[1], reverse=True) # sorted by values, return a list of tuples\n",
    "    x, y = zip(*sort_by_vals) # unpack a list of pairs into two tuples\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    \n",
    "    plt.bar(x,y)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    if x_label:\n",
    "        ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(\"Percentage of OA papers published\")\n",
    "    \n",
    "    ax.set_ylim([0,100])\n",
    "    \n",
    "    if plt_text:\n",
    "#     https://stackoverflow.com/a/8482667/530399\n",
    "        plt.text(0.7, 0.9,plt_text, ha='center', va='center', transform=ax.transAxes)\n",
    "    \n",
    "    if display_values:\n",
    "        for i, v in enumerate(y):\n",
    "            ax.text(i-.25, v + 3, str(round(v,3)), color='blue', fontweight='bold')\n",
    "    \n",
    "    plt.xticks(x, rotation='vertical')\n",
    "    \n",
    "    plt.savefig(save_fname+\".png\", bbox_inches='tight')\n",
    "    plt.savefig(save_fname+\".pdf\", bbox_inches='tight')\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_wiki_link_normalise(wikilink):\n",
    "#     Get the english name from the wiki\n",
    "\n",
    "#     print(wikilink)\n",
    "    \n",
    "    try:\n",
    "        last_slash_index = wikilink.rindex('/')\n",
    "        start_index = last_slash_index+1\n",
    "        uni_name = wikilink[start_index:]\n",
    "    except:\n",
    "        uni_name = \"\"\n",
    "#     Apply MAG normalisation to the name\n",
    "    return mag_normalisation_institution_names(uni_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A : Analysis Per University Per Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_year_bins = [0, 2010, 2013, 2016, 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plt_univ_papers_OA_stats(country_papers_OA_df, univs_name):\n",
    "    univs_oa_percent = {} # needed for plot data\n",
    "    univs_info = {}\n",
    "    \n",
    "    univs_not_found = []\n",
    "    univs_found = []\n",
    "    \n",
    "    for org_univ_name in set(univs_name):  # remove duplicate univ names in the THE list, if any\n",
    "#         print(org_univ_name)\n",
    "\n",
    "        THE_univ_name_normalised = mag_normalisation_institution_names(org_univ_name)\n",
    "    \n",
    "        '''\n",
    "        The dataframe that will be selected for the current univ is either :\n",
    "        1. When the MAG normalizedname column matches to THE_univ_name_normalised\n",
    "        or\n",
    "        2. When the MAG normalised(wikiname) matches to THE_univ_name_normalised -- this matches English names (in MAG wiki links as well as THE) of non English name (in MAG normalisedname or displayname) universities.\n",
    "        '''\n",
    "        univ_papers_df_set1 = country_papers_OA_df[country_papers_OA_df['normalizedname']==THE_univ_name_normalised]\n",
    "        \n",
    "        univ_papers_df_set2 = country_papers_OA_df[country_papers_OA_df['normalizedwikiname']==THE_univ_name_normalised]\n",
    "        \n",
    "        \n",
    "        # Concat and remove exact duplicates  -- https://stackoverflow.com/a/21317570/530399\n",
    "        univ_papers_df = pd.concat([univ_papers_df_set1, univ_papers_df_set2]).drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        count_total_univ_papers = len(univ_papers_df)\n",
    "        \n",
    "        \n",
    "        # For those I couldn't match/find their name, it is not fair to say that their OA count is 0. Should be excluded from the graph.\n",
    "        if count_total_univ_papers==0:\n",
    "            univs_not_found.append(org_univ_name+\"    @    \"+THE_univ_name_normalised)\n",
    "        else:\n",
    "            univs_found.append(org_univ_name)\n",
    "            \n",
    "            univs_info[org_univ_name] = {}\n",
    "            univs_info[org_univ_name][\"count_total_papers\"] = count_total_univ_papers\n",
    "            \n",
    "            # All (OA + unknown) \n",
    "            count_all_2007 = len(univ_papers_df[univ_papers_df['year']==2007])\n",
    "            count_all_2008 = len(univ_papers_df[univ_papers_df['year']==2008])\n",
    "            count_all_2009 = len(univ_papers_df[univ_papers_df['year']==2009])\n",
    "            count_all_2010 = len(univ_papers_df[univ_papers_df['year']==2010])\n",
    "            count_all_2011 = len(univ_papers_df[univ_papers_df['year']==2011])\n",
    "            count_all_2012 = len(univ_papers_df[univ_papers_df['year']==2012])\n",
    "            count_all_2013 = len(univ_papers_df[univ_papers_df['year']==2013])\n",
    "            count_all_2014 = len(univ_papers_df[univ_papers_df['year']==2014])\n",
    "            count_all_2015 = len(univ_papers_df[univ_papers_df['year']==2015])\n",
    "            count_all_2016 = len(univ_papers_df[univ_papers_df['year']==2016])\n",
    "            count_all_2017 = len(univ_papers_df[univ_papers_df['year']==2017])\n",
    "            count_all_2018 = len(univ_papers_df[univ_papers_df['year']==2018])\n",
    "            \n",
    "            \n",
    "            univs_info[org_univ_name][\"yearwise_all\"] = {}\n",
    "            univs_info[org_univ_name][\"yearwise_all\"][\"count_year\"] = {\"2008\":count_all_2008, \"2009\":count_all_2009, \"2010\":count_all_2010,\"2011\":count_all_2011,\"2012\":count_all_2012,\"2013\":count_all_2013,\"2014\":count_all_2014,\"2015\":count_all_2015,\"2016\":count_all_2016,\"2017\":count_all_2017,\"2018\":count_all_2018}\n",
    "            \n",
    "            \n",
    "            \n",
    "            # OA part\n",
    "            OA_univ_papers_df = univ_papers_df[univ_papers_df['is_OA']==\"true\"] # stored as a string in csv\n",
    "            unknown_univ_papers_df = univ_papers_df[univ_papers_df['is_OA']!=\"true\"] # stored as a string in csv\n",
    "            \n",
    "            count_OA_univ_papers = len(OA_univ_papers_df)\n",
    "            count_unknown_univ_papers = len(unknown_univ_papers_df)\n",
    "\n",
    "            univ_oa_percent = (count_OA_univ_papers*100.00)/count_total_univ_papers\n",
    "            univ_other_percent = (count_unknown_univ_papers*100.00)/count_total_univ_papers\n",
    "            \n",
    "            univs_oa_percent[org_univ_name] = univ_oa_percent\n",
    "        \n",
    "            \n",
    "            \n",
    "            univs_info[org_univ_name][\"count_OA_papers\"] = count_OA_univ_papers\n",
    "            univs_info[org_univ_name][\"percent_OA_papers\"] = univ_oa_percent\n",
    "            \n",
    "            univs_info[org_univ_name][\"count_unknown_papers\"] = count_unknown_univ_papers\n",
    "            univs_info[org_univ_name][\"percent_unknown_papers\"] = univ_other_percent\n",
    "            \n",
    "            univs_info[org_univ_name][\"count_total_papers\"] = count_total_univ_papers\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Further to get a yearwise breakdown of oa papers\n",
    "            univs_info[org_univ_name][\"yearwise_OA\"] = {}            \n",
    "            \n",
    "            count_oa_2007 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2007])\n",
    "            count_oa_2008 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2008])\n",
    "            count_oa_2009 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2009])\n",
    "            count_oa_2010 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2010])\n",
    "            count_oa_2011 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2011])\n",
    "            count_oa_2012 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2012])\n",
    "            count_oa_2013 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2013])\n",
    "            count_oa_2014 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2014])\n",
    "            count_oa_2015 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2015])\n",
    "            count_oa_2016 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2016])\n",
    "            count_oa_2017 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2017])\n",
    "            count_oa_2018 = len(OA_univ_papers_df[OA_univ_papers_df['year']==2018])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            univs_info[org_univ_name][\"yearwise_OA\"][\"count_year\"] = {\"2007\":count_oa_2007, \"2008\":count_oa_2008,\n",
    "                                                                  \"2009\":count_oa_2009, \"2010\":count_oa_2010,\n",
    "                                                                  \"2011\":count_oa_2011, \"2012\":count_oa_2012,\n",
    "                                                                  \"2013\":count_oa_2013, \"2014\":count_oa_2014,\n",
    "                                                                  \"2015\":count_oa_2015, \"2016\":count_oa_2016,\n",
    "                                                                  \"2017\":count_oa_2017, \"2018\":count_oa_2018} \n",
    "            \n",
    "            \n",
    "            bucket_year_groups = OA_univ_papers_df.groupby(pd.cut(OA_univ_papers_df.year, pub_year_bins))\n",
    "            bucket_year_groups_count_records = bucket_year_groups.size().to_dict()\n",
    "            #  for easy readbility\n",
    "            remapped = {}\n",
    "            remapped[\"0-2010\"] = bucket_year_groups_count_records[pd.Interval(0, 2010, closed='right')]\n",
    "            remapped[\"2011-2013\"] = bucket_year_groups_count_records[pd.Interval(2010, 2013, closed='right')]\n",
    "            remapped[\"2014-2016\"] = bucket_year_groups_count_records[pd.Interval(2013, 2016, closed='right')]\n",
    "            remapped[\"2017-2019\"] = bucket_year_groups_count_records[pd.Interval(2016, 2019, closed='right')]\n",
    "            \n",
    "            univs_info[org_univ_name][\"yearwise_OA\"][\"count_intervals\"] = remapped\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             Note: This is the growth rate per year.\n",
    "            growth_rate = {}  # change divided by the time it took to make that change\n",
    "            growth_rate[\"2008\"] = (count_oa_2008 - count_oa_2007)/1.00\n",
    "            growth_rate[\"2009\"] = (count_oa_2009 - count_oa_2008)/1.00\n",
    "            growth_rate[\"2010\"] = (count_oa_2010 - count_oa_2009)/1.00\n",
    "            growth_rate[\"2011\"] = (count_oa_2011 - count_oa_2010)/1.00\n",
    "            growth_rate[\"2012\"] = (count_oa_2012 - count_oa_2011)/1.00\n",
    "            growth_rate[\"2013\"] = (count_oa_2013 - count_oa_2012)/1.00\n",
    "            growth_rate[\"2014\"] = (count_oa_2014 - count_oa_2013)/1.00\n",
    "            growth_rate[\"2015\"] = (count_oa_2015 - count_oa_2014)/1.00\n",
    "            growth_rate[\"2016\"] = (count_oa_2016 - count_oa_2015)/1.00\n",
    "            growth_rate[\"2017\"] = (count_oa_2017 - count_oa_2016)/1.00\n",
    "            growth_rate[\"2018\"] = (count_oa_2018 - count_oa_2017)/1.00\n",
    "            \n",
    "            \n",
    "            univs_info[org_univ_name][\"yearwise_OA\"][\"growth_rate\"] = growth_rate\n",
    "    \n",
    "    bar_fig = create_OA_percent_bar_chart(univs_oa_percent, save_fname = join(output_dir,country_name+\"_\"+'OA_percent') , x_label = (\"Universities in \"+country_name), plt_text = ('Total Count of Universities = '+str(len(univs_oa_percent))) )\n",
    "    return bar_fig, univs_info, univs_not_found, univs_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory to save results\n",
    "os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "all_countries_plot = {}\n",
    "all_countries_all_univs_OA_info = {}\n",
    "all_countries_univs_found_not_found = {}\n",
    "\n",
    "for country_name,univs_name in cfg['data']['all_THE_institutions_by_country'].items():\n",
    "    print(\"\\nProcesing for dataset of univs in \"+country_name+\"\\n\")\n",
    "    all_countries_plot[country_name] = {}\n",
    "    all_countries_univs_found_not_found[country_name] =  {}\n",
    "    \n",
    "    # CSV has repeated header from multiple partitions of the merge on pyspark csv output. Hence need to treat as string.\n",
    "    country_papers_OA_df = pd.read_csv(join(root,\"data/processed/OA_status_\"+country_name+\"_papers.csv\"), header=0, sep=\",\", dtype={'is_OA': object, \"url_lists_as_string\": object, \"year\": object, \"wikipage\": object})  # object means string\n",
    "    # Then eliminate problematic lines\n",
    "    #  temp fix until spark csv merge header issue is resolved -- the header line is present in each re-partition's output csv\n",
    "    country_papers_OA_df.drop(country_papers_OA_df[country_papers_OA_df.paperid == \"paperid\"].index, inplace=True)\n",
    "    # Then reset dtypes as needed.\n",
    "    country_papers_OA_df = country_papers_OA_df.astype({'year':int})  # todo : for other types too including is_OA and update the check method to boolean type\n",
    "    \n",
    "    # Finally, create a new column named normalizedwikiname. This is helpful for matching english names of non-english universities. Eg: get \"federal university of health sciences of porto alegre\" for \"universidade federal de ciencias da saude de porto alegre\" using the wikilink which contains \"universidade federal de ciencias da saude de porto alegre\" in it.\n",
    "    country_papers_OA_df[\"normalizedwikiname\"] = country_papers_OA_df['wikipage'].apply(mag_wiki_link_normalise)\n",
    "    \n",
    "    \n",
    "    country_plot, univs_info, univs_not_found, univs_found = get_plt_univ_papers_OA_stats(country_papers_OA_df, univs_name)\n",
    "    \n",
    "    all_countries_plot[country_name] =  country_plot\n",
    "    all_countries_all_univs_OA_info[country_name] =  univs_info\n",
    "    \n",
    "    count_total_univs = len(univs_not_found) + len(univs_found)\n",
    "    \n",
    "    not_found_details = {}\n",
    "    not_found_details['univ_names'] = univs_not_found\n",
    "    not_found_details['count_univs'] = len(univs_not_found)\n",
    "    not_found_details['percent_univs'] = (len(univs_not_found)*100.00)/count_total_univs\n",
    "    \n",
    "    found_details = {}\n",
    "    found_details['univ_names'] = univs_found\n",
    "    found_details['count_univs'] = len(univs_found)\n",
    "    found_details['percent_univs'] = (len(univs_found)*100.00)/count_total_univs\n",
    "    \n",
    "    \n",
    "    all_details = {}\n",
    "    all_details['count_univs'] = count_total_univs\n",
    "    \n",
    "    all_countries_univs_found_not_found[country_name]['not_found'] = not_found_details\n",
    "    all_countries_univs_found_not_found[country_name]['found'] = found_details\n",
    "    all_countries_univs_found_not_found[country_name]['all'] = all_details\n",
    "    \n",
    "    \n",
    "        \n",
    "    print(\"Saved plot for dataset of \"+country_name+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write text files with the infos\n",
    "\n",
    "with open(join(output_dir,'all_countries_univs_found_not_found.txt'), 'w') as file:\n",
    "     file.write(json.dumps(all_countries_univs_found_not_found, sort_keys=True, indent=4, ensure_ascii=False))\n",
    "        \n",
    "with open(join(output_dir,'all_countries_all_univs_OA_info.txt'), 'w') as file:\n",
    "     file.write(json.dumps(all_countries_all_univs_OA_info, sort_keys=True, indent=4, ensure_ascii=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Test country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_country = \"russia\"\n",
    "test_country = \"brazil\"\n",
    "# test_country = \"uk\"\n",
    "# test_country = \"usa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_countries_plot[test_country].savefig(join(output_dir,test_country+\"_\"+'OA.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries_plot[test_country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_countries_univs_found_not_found[test_country]['not_found']['univ_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries_univs_found_not_found[test_country]['not_found']['count_univs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_univ = \"Altai State Technical University\"\n",
    "test_univ = \"Universidade Luterana do Brasil (ULBRA)\"\n",
    "# test_univ = \"Brighton and Sussex Medical School\"\n",
    "# test_univ = \"central baptist college\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries_all_univs_OA_info[test_country][test_univ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_OA_value = 100.00\n",
    "for key,val in all_countries_all_univs_OA_info[test_country].items():\n",
    "    if val['percent_OA_papers'] == test_OA_value:\n",
    "        print(key)\n",
    "        print(val)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_OA_papers_count = 0\n",
    "max_OA_papers_uni = None\n",
    "for key,val in all_countries_all_univs_OA_info[test_country].items():\n",
    "    if val['count_OA_papers'] > max_OA_papers_count:\n",
    "        max_OA_papers_uni = key\n",
    "        max_OA_papers_count = val['count_OA_papers']\n",
    "print(max_OA_papers_uni)\n",
    "print(all_countries_all_univs_OA_info[test_country][max_OA_papers_uni])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Analysis at Country Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(output_dir,'all_countries_all_univs_OA_info.txt')) as file:\n",
    "     all_countries_all_univs_OA_info = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_countries_all_univs_OA_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_oa_info = {}\n",
    "countries_oa_percents = {}  # needed for plot.\n",
    "\n",
    "for key,val in all_countries_all_univs_OA_info.items():\n",
    "#     print(key)\n",
    "    count_country_OA_papers = 0\n",
    "    count_country_unknown_papers = 0\n",
    "    \n",
    "    count_yearwise_0_to_2010 = 0\n",
    "    count_yearwise_2011_to_2013 = 0\n",
    "    count_yearwise_2014_to_2016 = 0\n",
    "    count_yearwise_2017_to_2019 = 0\n",
    "    \n",
    "    \n",
    "    count_oa_2007 = 0\n",
    "    count_oa_2008 = 0\n",
    "    count_oa_2009 = 0\n",
    "    count_oa_2010 = 0\n",
    "    count_oa_2011 = 0\n",
    "    count_oa_2012 = 0\n",
    "    count_oa_2013 = 0\n",
    "    count_oa_2014 = 0\n",
    "    count_oa_2015 = 0\n",
    "    count_oa_2016 = 0\n",
    "    count_oa_2017 = 0\n",
    "    count_oa_2018 = 0\n",
    "    \n",
    "    \n",
    "    count_all_2008 = 0\n",
    "    count_all_2009 = 0\n",
    "    count_all_2010 = 0\n",
    "    count_all_2011 = 0\n",
    "    count_all_2012 = 0\n",
    "    count_all_2013 = 0\n",
    "    count_all_2014 = 0\n",
    "    count_all_2015 = 0\n",
    "    count_all_2016 = 0\n",
    "    count_all_2017 = 0\n",
    "    count_all_2018 = 0\n",
    "    \n",
    "    \n",
    "    for univ_name,univ_oa_details in val.items():\n",
    "        count_country_OA_papers = count_country_OA_papers + univ_oa_details['count_OA_papers']\n",
    "        count_country_unknown_papers = count_country_unknown_papers + univ_oa_details['count_unknown_papers']\n",
    "        \n",
    "        # Lets get the sum of count of OA in the selected intervals\n",
    "        count_yearwise_0_to_2010 = count_yearwise_0_to_2010 + univ_oa_details[\"yearwise_OA\"][\"count_intervals\"][\"0-2010\"]\n",
    "        count_yearwise_2011_to_2013 = count_yearwise_2011_to_2013 + univ_oa_details[\"yearwise_OA\"][\"count_intervals\"][\"2011-2013\"]\n",
    "        count_yearwise_2014_to_2016 = count_yearwise_2014_to_2016 + univ_oa_details[\"yearwise_OA\"][\"count_intervals\"][\"2014-2016\"]\n",
    "        count_yearwise_2017_to_2019 = count_yearwise_2017_to_2019 + univ_oa_details[\"yearwise_OA\"][\"count_intervals\"][\"2017-2019\"]\n",
    "        \n",
    "        # The sum of count of oa in specific years -- needed to find growth rate\n",
    "        count_oa_2007 = count_oa_2007 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2007\"]\n",
    "        count_oa_2008 = count_oa_2008 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2008\"]\n",
    "        count_oa_2009 = count_oa_2009 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2009\"]\n",
    "        count_oa_2010 = count_oa_2010 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2010\"]\n",
    "        count_oa_2011 = count_oa_2011 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2011\"]\n",
    "        count_oa_2012 = count_oa_2012 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2012\"]\n",
    "        count_oa_2013 = count_oa_2013 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2013\"]\n",
    "        count_oa_2014 = count_oa_2014 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2014\"]\n",
    "        count_oa_2015 = count_oa_2015 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2015\"]\n",
    "        count_oa_2016 = count_oa_2016 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2016\"]\n",
    "        count_oa_2017 = count_oa_2017 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2017\"]\n",
    "        count_oa_2018 = count_oa_2018 + univ_oa_details[\"yearwise_OA\"][\"count_year\"][\"2018\"]\n",
    "        \n",
    "        \n",
    "        # The sum of count of all papers in specific years -- needed to find oa percent within each year\n",
    "        count_all_2008 = count_all_2008 + univ_oa_details[\"yearwise_all\"][\"count_year\"][\"2008\"]\n",
    "        count_all_2009 = count_all_2009 + univ_oa_details[\"yearwise_all\"][\"count_year\"][\"2009\"]\n",
    "        count_all_2010 = count_all_2010 + univ_oa_details[\"yearwise_all\"][\"count_year\"][\"2010\"]\n",
    "        count_all_2011 = count_all_2011 + univ_oa_details[\"yearwise_all\"][\"count_year\"][\"2011\"]\n",
    "        count_all_2012 = count_all_2012 + univ_oa_details[\"yearwise_all\"][\"count_year\"][\"2012\"]\n",
    "        count_all_2013 = count_all_2013 + univ_oa_details[\"yearwise_all\"][\"count_year\"][\"2013\"]\n",
    "        count_all_2014 = count_all_2014 + univ_oa_details[\"yearwise_all\"][\"count_year\"][\"2014\"]\n",
    "        count_all_2015 = count_all_2015 + univ_oa_details[\"yearwise_all\"][\"count_year\"][\"2015\"]\n",
    "        count_all_2016 = count_all_2016 + univ_oa_details[\"yearwise_all\"][\"count_year\"][\"2016\"]\n",
    "        count_all_2017 = count_all_2017 + univ_oa_details[\"yearwise_all\"][\"count_year\"][\"2017\"]\n",
    "        count_all_2018 = count_all_2018 + univ_oa_details[\"yearwise_all\"][\"count_year\"][\"2018\"]\n",
    "    \n",
    "    \n",
    "    total_country_papers = count_country_OA_papers + count_country_unknown_papers\n",
    "    percent_OA_country = (count_country_OA_papers * 100.00)/total_country_papers\n",
    "    percent_unknown_country = (count_country_unknown_papers * 100.00)/total_country_papers\n",
    "    \n",
    "    countries_oa_info[key] = {}\n",
    "    countries_oa_info[key]['count_OA_papers'] = count_country_OA_papers\n",
    "    countries_oa_info[key]['count_unknown_papers'] = count_country_unknown_papers    \n",
    "    countries_oa_info[key]['percent_OA_papers'] = percent_OA_country\n",
    "    countries_oa_info[key]['percent_unknown_papers'] = percent_unknown_country\n",
    "    countries_oa_info[key]['count_total_papers'] = total_country_papers\n",
    "    \n",
    "    countries_oa_info[key][\"yearwise_OA\"] = {}\n",
    "    \n",
    "    countries_oa_info[key][\"yearwise_OA\"][\"count_intervals\"] = {\"0-2010\": count_yearwise_0_to_2010,\n",
    "                                                                \"2011-2013\": count_yearwise_2011_to_2013,\n",
    "                                                               \"2014-2016\": count_yearwise_2014_to_2016,\n",
    "                                                                \"2017-2019\": count_yearwise_2017_to_2019}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    countries_oa_info[key][\"yearwise_OA\"][\"count_year\"] = {\"2007\":count_oa_2007, \"2008\":count_oa_2008,\n",
    "                                                           \"2009\":count_oa_2009, \"2010\":count_oa_2010,\n",
    "                                                           \"2011\":count_oa_2011, \"2012\":count_oa_2012,\n",
    "                                                           \"2013\":count_oa_2013, \"2014\":count_oa_2014,\n",
    "                                                           \"2015\":count_oa_2015, \"2016\":count_oa_2016,\n",
    "                                                           \"2017\":count_oa_2017, \"2018\":count_oa_2018} \n",
    "    \n",
    "    # Lets find the percentage OA in each year\n",
    "    countries_oa_info[key][\"yearwise_OA\"][\"percent_year\"] = {\n",
    "        \"2008\":(count_oa_2008*100.00)/count_all_2008,\n",
    "       \"2009\":(count_oa_2009*100.00)/count_all_2009,\n",
    "        \"2010\":(count_oa_2010*100.00)/count_all_2010,\n",
    "       \"2011\":(count_oa_2011*100.00)/count_all_2011,\n",
    "        \"2012\":(count_oa_2012*100.00)/count_all_2012,\n",
    "       \"2013\":(count_oa_2013*100.00)/count_all_2013,\n",
    "        \"2014\":(count_oa_2014*100.00)/count_all_2014,\n",
    "       \"2015\":(count_oa_2015*100.00)/count_all_2015, \n",
    "        \"2016\":(count_oa_2016*100.00)/count_all_2016,\n",
    "       \"2017\":(count_oa_2017*100.00)/count_all_2017,\n",
    "        \"2018\":(count_oa_2018*100.00)/count_all_2018\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Lets also find the growth within each intervals\n",
    "    growth_rate = {}  # change divided by the time it took to make that change\n",
    "    growth_rate[\"2008\"] = (count_oa_2008 - count_oa_2007)/1.00\n",
    "    growth_rate[\"2009\"] = (count_oa_2009 - count_oa_2008)/1.00\n",
    "    growth_rate[\"2010\"] = (count_oa_2010 - count_oa_2009)/1.00\n",
    "    growth_rate[\"2011\"] = (count_oa_2011 - count_oa_2010)/1.00\n",
    "    growth_rate[\"2012\"] = (count_oa_2012 - count_oa_2011)/1.00\n",
    "    growth_rate[\"2013\"] = (count_oa_2013 - count_oa_2012)/1.00\n",
    "    growth_rate[\"2014\"] = (count_oa_2014 - count_oa_2013)/1.00\n",
    "    growth_rate[\"2015\"] = (count_oa_2015 - count_oa_2014)/1.00\n",
    "    growth_rate[\"2016\"] = (count_oa_2016 - count_oa_2015)/1.00\n",
    "    growth_rate[\"2017\"] = (count_oa_2017 - count_oa_2016)/1.00\n",
    "    growth_rate[\"2018\"] = (count_oa_2018 - count_oa_2017)/1.00\n",
    "    countries_oa_info[key][\"yearwise_OA\"][\"growth_rate\"] = growth_rate\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    countries_oa_percents[key] = percent_OA_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(output_dir,'all_countries_OA_info.txt'), 'w') as file:\n",
    "     file.write(json.dumps(countries_oa_info, sort_keys=True, indent=4, ensure_ascii=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_oa_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_oa_percent_bar_plot = create_OA_percent_bar_chart(countries_oa_percents, save_fname = join(output_dir,\"all_countries_OA_percent\"), x_label = \"Countries\", display_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_oa_percent_bar_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triple_bar_chart(oa_info_dict, save_fname, x_label=None):\n",
    "    '''\n",
    "    Contains plot of count OA, count Unknown and count Total. The % OA value is too small for this plot and is therefore separately shown in the other graph.\n",
    "    '''\n",
    "    \n",
    "    #  Sort by Percentage OA   \n",
    "    #  https://stackoverflow.com/a/37266356/530399\n",
    "    sort_by_vals = sorted(oa_info_dict.items(), key=lambda kv: kv[1]['percent_OA_papers'], reverse=True) # sorted by values, return a list of tuples\n",
    "    \n",
    "    names = [x for (x,y) in sort_by_vals]\n",
    "    \n",
    "    # set width of bar\n",
    "    barWidth = 0.3\n",
    "    \n",
    "    \n",
    "    y_values_scale_down_factor = 10000\n",
    "    # set height of bar -- scale down by 10k   \n",
    "    bars_oa_count = [y['count_OA_papers']/y_values_scale_down_factor for (x,y) in sort_by_vals]\n",
    "    bars_unknown_count = [y['count_unknown_papers']/y_values_scale_down_factor for (x,y) in sort_by_vals]\n",
    "    bars_total_count = [(y['count_OA_papers']+y['count_unknown_papers'])/y_values_scale_down_factor for (x,y) in sort_by_vals]\n",
    "    \n",
    "    \n",
    "    sep_between_group_bars = 2\n",
    "    # Set position of bar on X axis\n",
    "    r1 = np.arange(len(bars_oa_count))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    r3 = [x + barWidth for x in r2]\n",
    "\n",
    "    # Make the plot\n",
    "    plt.figure(figsize=(15,10))\n",
    "    \n",
    "    plt.bar(r1, bars_oa_count, color='blue', width=barWidth, edgecolor='white', label='Count OA')\n",
    "    plt.bar(r2, bars_unknown_count, color='red', width=barWidth, edgecolor='white', label='Count Unknown')\n",
    "    plt.bar(r3, bars_total_count, color='green', width=barWidth, edgecolor='white', label='Total Papers Count')\n",
    "\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    if x_label:\n",
    "        ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(\"Count of OA, Unknown and Total Papers (Expressed in terms of 10K) \")\n",
    "    \n",
    "    #     https://stackoverflow.com/a/8482667/530399\n",
    "#     plt.text(0.7, 0.9,\"Numbers are in terms of 10K\", ha='center', va='center', transform=ax.transAxes)\n",
    "    \n",
    "    for p in ax.patches:\n",
    "        h = p.get_height()\n",
    "        x = p.get_x()+p.get_width()/2.\n",
    "        ax.annotate(\"%g\" % h, xy=(x,h), xytext=(0,4), rotation=90,  textcoords=\"offset points\", ha=\"center\", va=\"bottom\")\n",
    "    \n",
    "    \n",
    "    # Add xticks on the middle of the group bars\n",
    "    plt.xticks([r + barWidth for r in range(len(bars_oa_count))], names, rotation='vertical')\n",
    "    \n",
    "    \n",
    "    # Create legend & Show graphic\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "    plt.savefig(save_fname+\".png\", bbox_inches='tight')\n",
    "    plt.savefig(save_fname+\".pdf\", bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_oa_info_bar_plot = create_triple_bar_chart(countries_oa_info, save_fname = join(output_dir,\"all_countries_OA_info\"), x_label = \"Countries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_oa_info_bar_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_OA_growth_line_chart(countries_oa_info, save_fname, x_label = \"Year\", plt_text=None):\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    \n",
    "    country_names_list = []\n",
    "    markers = ['o', 'x', 'v', 's', '*', '+', 'D', '|']\n",
    "    for country_name,oa_info in countries_oa_info.items():\n",
    "        \n",
    "        growth_rate = oa_info[\"yearwise_OA\"][\"growth_rate\"]\n",
    "        # sort by year\n",
    "        #  https://stackoverflow.com/a/37266356/530399\n",
    "        sort_by_year = sorted(growth_rate.items(), key=lambda kv: int(kv[0]))\n",
    "        years, growth_rates = zip(*sort_by_year) # unpack a list of pairs into two tuples\n",
    "        \n",
    "        plt.plot(years,growth_rates, linewidth=4, markersize=12, marker=markers[len(country_names_list)])\n",
    "        \n",
    "        country_names_list.append(country_name)\n",
    "        \n",
    "        \n",
    "    \n",
    "    ax = plt.gca()\n",
    "    if x_label:\n",
    "        ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(\"Growth Rate of OA papers per year\")\n",
    "    \n",
    "    if plt_text:\n",
    "#     https://stackoverflow.com/a/8482667/530399\n",
    "        plt.text(0.7, 0.9,plt_text, ha='center', va='center', transform=ax.transAxes)\n",
    "    \n",
    "#     plt.xticks(years)\n",
    "    plt.legend(country_names_list, loc='upper left')\n",
    "    \n",
    "    plt.savefig(save_fname+\".png\", bbox_inches='tight')\n",
    "    plt.savefig(save_fname+\".pdf\", bbox_inches='tight')\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_OA_growth_line_plot = create_OA_growth_line_chart(countries_oa_info, save_fname = join(output_dir,\"all_countries_OA_growth\"), x_label = \"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_OA_growth_line_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yearwise_OA_percent_line_chart(countries_oa_info, save_fname, x_label = \"Year\", plt_text=None):\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    \n",
    "    country_names_list = []\n",
    "    markers = ['o', 'x', 'v', 's', '*', '+', 'D', '|']\n",
    "    for country_name,oa_info in countries_oa_info.items():\n",
    "        \n",
    "        percent_oa = oa_info[\"yearwise_OA\"][\"percent_year\"]\n",
    "        # sort by year\n",
    "        #  https://stackoverflow.com/a/37266356/530399\n",
    "        sort_by_year = sorted(percent_oa.items(), key=lambda kv: int(kv[0]))\n",
    "        years, percent_oas = zip(*sort_by_year) # unpack a list of pairs into two tuples\n",
    "        \n",
    "        plt.plot(years,percent_oas, linewidth=4, markersize=12, marker=markers[len(country_names_list)])\n",
    "        \n",
    "        country_names_list.append(country_name)\n",
    "        \n",
    "        \n",
    "    \n",
    "    ax = plt.gca()\n",
    "    if x_label:\n",
    "        ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(\"% of OA paper published in each year\")\n",
    "    \n",
    "    if plt_text:\n",
    "#     https://stackoverflow.com/a/8482667/530399\n",
    "        plt.text(0.7, 0.9,plt_text, ha='center', va='center', transform=ax.transAxes)\n",
    "    \n",
    "#     plt.xticks(years)\n",
    "    plt.legend(country_names_list, loc='upper left')\n",
    "    \n",
    "    plt.savefig(save_fname+\".png\", bbox_inches='tight')\n",
    "    plt.savefig(save_fname+\".pdf\", bbox_inches='tight')\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_OA_percent_each_year_line_plot = create_yearwise_OA_percent_line_chart(countries_oa_info, save_fname = join(output_dir,\"all_countries_OA_percent_each_year\"), x_label = \"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_OA_percent_each_year_line_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_oa_info['brazil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\\nCompleted!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
